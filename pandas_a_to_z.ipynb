{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> Pandas </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pandas using pip\n",
    "pip install pandas\n",
    "(or)\n",
    "pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upgrade Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Pandas Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librart\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rosaline Franklin</td>\n",
       "      <td>Chemist</td>\n",
       "      <td>1920-07-25</td>\n",
       "      <td>1958-04-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William Gosset</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>1876-06-13</td>\n",
       "      <td>1937-10-16</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name    Occupation        Born        Died  Age\n",
       "0  Rosaline Franklin       Chemist  1920-07-25  1958-04-16   37\n",
       "1     William Gosset  Statistician  1876-06-13  1937-10-16   61"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientists = pd.DataFrame({\n",
    "'Name': ['Rosaline Franklin', 'William Gosset'],\n",
    "'Occupation': ['Chemist', 'Statistician'],\n",
    "'Born': ['1920-07-25', '1876-06-13'],\n",
    "'Died': ['1958-04-16', '1937-10-16'],\n",
    "'Age': [37, 61]})\n",
    "scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Born</th>\n",
       "      <th>Died</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rosaline Franklin</th>\n",
       "      <td>Chemist</td>\n",
       "      <td>1920-07-25</td>\n",
       "      <td>1958-04-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William Gosset</th>\n",
       "      <td>Statistician</td>\n",
       "      <td>1876-06-13</td>\n",
       "      <td>1937-10-16</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Occupation        Born        Died  Age\n",
       "Rosaline Franklin       Chemist  1920-07-25  1958-04-16   37\n",
       "William Gosset     Statistician  1876-06-13  1937-10-16   61"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientists = pd.DataFrame(\n",
    "data = {'Occupation': ['Chemist', 'Statistician'],\n",
    "'Born': ['1920-07-25', '1876-06-13'],\n",
    "'Died': ['1958-04-16', '1937-10-16'],\n",
    "'Age': [37, 61]},\n",
    "index = ['Rosaline Franklin', 'William Gosset'],\n",
    ")\n",
    "scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame from List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1       2\n",
      "0   Spark  20000  30days\n",
      "1  Pandas  25000  40days\n"
     ]
    }
   ],
   "source": [
    "# Create pandas DataFrame from List\n",
    "tech = [ [\"Spark\",20000, \"30days\"], \n",
    "                 [\"Pandas\",25000, \"40days\"]\n",
    "               ]\n",
    "df=pd.DataFrame(tech)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration\n",
      "a   Spark  20000   30days\n",
      "b  Pandas  25000   40days\n"
     ]
    }
   ],
   "source": [
    "# Add Column & Row Labels to the DataFrame\n",
    "column_names=[\"Courses\",\"Fee\",\"Duration\"]\n",
    "row_label=[\"a\",\"b\"]\n",
    "df=pd.DataFrame(tech,columns=column_names,index=row_label)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame from Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration\n",
      "0   Spark  20000   30days\n",
      "1  Pandas  25000   40days\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame from Dict\n",
    "tech = {\n",
    "    'Courses':[\"Spark\",\"Pandas\"],\n",
    "    'Fee' :[20000,25000],\n",
    "    'Duration':['30days','40days']\n",
    "              }\n",
    "df = pd.DataFrame(tech)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration\n",
      "r1   Spark  20000   30days\n",
      "r2  Pandas  25000   40days\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with Index.\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"Pandas\"],\n",
    "    'Fee' :[20000,25000],\n",
    "    'Duration':['30days','40days']\n",
    "              }\n",
    "index_label=[\"r1\",\"r2\"]\n",
    "df = pd.DataFrame(technologies, index=index_label)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    orange\n",
       "1        30\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(['orange',30])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign index to above series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name       Jahanzaib Jaan\n",
       "Address           Bhalwal\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series(['Jahanzaib Jaan', 'Bhalwal'],\n",
    "index=['Name', 'Address'])\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Series from Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         math\n",
       "1      physics\n",
       "2    chemistry\n",
       "3      biology\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array(['math', 'physics', 'chemistry', 'biology'])\n",
    "series = pd.Series(data)\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('D:/git/jaan_repo/datasets/drinks.csv')\n",
    "df1 = pd.read_csv('D:/git/jaan_repo/datasets/IPL_matches(2008-2016).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from a tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_table('filename.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from a excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel('filename.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'website_link.com'\n",
    "# df = pd.read_html(url)\n",
    "# df = pd.read_csv(url)\n",
    "# df = pd.read_json(url)\n",
    "# df = pd.read_table(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import seaborn library\n",
    "# import seaborn as sns\n",
    "# # load dataset\n",
    "# df = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('filename.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>beer_servings</th>\n",
       "      <th>spirit_servings</th>\n",
       "      <th>wine_servings</th>\n",
       "      <th>total_litres_of_pure_alcohol</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>89</td>\n",
       "      <td>132</td>\n",
       "      <td>54</td>\n",
       "      <td>4.9</td>\n",
       "      <td>EU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>245</td>\n",
       "      <td>138</td>\n",
       "      <td>312</td>\n",
       "      <td>12.4</td>\n",
       "      <td>EU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>217</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>5.9</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  beer_servings  spirit_servings  wine_servings  \\\n",
       "0  Afghanistan              0                0              0   \n",
       "1      Albania             89              132             54   \n",
       "2      Algeria             25                0             14   \n",
       "3      Andorra            245              138            312   \n",
       "4       Angola            217               57             45   \n",
       "\n",
       "   total_litres_of_pure_alcohol continent  \n",
       "0                           0.0        AS  \n",
       "1                           4.9        EU  \n",
       "2                           0.7        AF  \n",
       "3                          12.4        EU  \n",
       "4                           5.9        AF  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>beer_servings</th>\n",
       "      <th>spirit_servings</th>\n",
       "      <th>wine_servings</th>\n",
       "      <th>total_litres_of_pure_alcohol</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>333</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  beer_servings  spirit_servings  wine_servings  \\\n",
       "188  Venezuela            333              100              3   \n",
       "189    Vietnam            111                2              1   \n",
       "190      Yemen              6                0              0   \n",
       "191     Zambia             32               19              4   \n",
       "192   Zimbabwe             64               18              4   \n",
       "\n",
       "     total_litres_of_pure_alcohol continent  \n",
       "188                           7.7        SA  \n",
       "189                           2.0        AS  \n",
       "190                           0.1        AS  \n",
       "191                           2.5        AF  \n",
       "192                           4.7        AF  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the no of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'beer_servings', 'spirit_servings', 'wine_servings',\n",
       "       'total_litres_of_pure_alcohol', 'continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the detail of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'beer_servings',\n",
       " 'spirit_servings',\n",
       " 'wine_servings',\n",
       " 'total_litres_of_pure_alcohol',\n",
       " 'continent']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see column names in list format\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see no of rows only\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see no of columns only\n",
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 6 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   country                       193 non-null    object \n",
      " 1   beer_servings                 193 non-null    int64  \n",
      " 2   spirit_servings               193 non-null    int64  \n",
      " 3   wine_servings                 193 non-null    int64  \n",
      " 4   total_litres_of_pure_alcohol  193 non-null    float64\n",
      " 5   continent                     170 non-null    object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_servings</th>\n",
       "      <th>spirit_servings</th>\n",
       "      <th>wine_servings</th>\n",
       "      <th>total_litres_of_pure_alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>106.160622</td>\n",
       "      <td>80.994819</td>\n",
       "      <td>49.450777</td>\n",
       "      <td>4.717098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>101.143103</td>\n",
       "      <td>88.284312</td>\n",
       "      <td>79.697598</td>\n",
       "      <td>3.773298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>188.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>376.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>14.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       beer_servings  spirit_servings  wine_servings  \\\n",
       "count     193.000000       193.000000     193.000000   \n",
       "mean      106.160622        80.994819      49.450777   \n",
       "std       101.143103        88.284312      79.697598   \n",
       "min         0.000000         0.000000       0.000000   \n",
       "25%        20.000000         4.000000       1.000000   \n",
       "50%        76.000000        56.000000       8.000000   \n",
       "75%       188.000000       128.000000      59.000000   \n",
       "max       376.000000       438.000000     370.000000   \n",
       "\n",
       "       total_litres_of_pure_alcohol  \n",
       "count                    193.000000  \n",
       "mean                       4.717098  \n",
       "std                        3.773298  \n",
       "min                        0.000000  \n",
       "25%                        1.300000  \n",
       "50%                        4.200000  \n",
       "75%                        7.200000  \n",
       "max                       14.400000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Pandas Functions </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Data Types </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                          object\n",
       "beer_servings                     int64\n",
       "spirit_servings                   int64\n",
       "wine_servings                     int64\n",
       "total_litres_of_pure_alcohol    float64\n",
       "continent                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the data type of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change int to object(string)\n",
    "df['beer_servings'] = df['beer_servings'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.beer_servings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change str into int\n",
    "df['beer_servings'] = df['beer_servings'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.beer_servings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change float into int\n",
    "df['total_litres_of_pure_alcohol_int'] = df['total_litres_of_pure_alcohol'].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       5\n",
       "2       1\n",
       "3      12\n",
       "4       6\n",
       "       ..\n",
       "188     8\n",
       "189     2\n",
       "190     0\n",
       "191     2\n",
       "192     5\n",
       "Name: total_litres_of_pure_alcohol, Length: 193, dtype: int32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_litres_of_pure_alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>beer_servings</th>\n",
       "      <th>spirit_servings</th>\n",
       "      <th>wine_servings</th>\n",
       "      <th>total_litres_of_pure_alcohol</th>\n",
       "      <th>continent</th>\n",
       "      <th>total_litres_of_pure_alcohol_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>89</td>\n",
       "      <td>132</td>\n",
       "      <td>54</td>\n",
       "      <td>4.9</td>\n",
       "      <td>EU</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>AF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>245</td>\n",
       "      <td>138</td>\n",
       "      <td>312</td>\n",
       "      <td>12.4</td>\n",
       "      <td>EU</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>217</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>5.9</td>\n",
       "      <td>AF</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  beer_servings  spirit_servings  wine_servings  \\\n",
       "0  Afghanistan              0                0              0   \n",
       "1      Albania             89              132             54   \n",
       "2      Algeria             25                0             14   \n",
       "3      Andorra            245              138            312   \n",
       "4       Angola            217               57             45   \n",
       "\n",
       "   total_litres_of_pure_alcohol continent  total_litres_of_pure_alcohol_int  \n",
       "0                           0.0        AS                                 0  \n",
       "1                           4.9        EU                                 5  \n",
       "2                           0.7        AF                                 1  \n",
       "3                          12.4        EU                                12  \n",
       "4                           5.9        AF                                 6  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change mix( string + numeric) into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CN'] = pd.to_numeric(df['CN'], errors='coerce').astype('int64')\n",
    "\n",
    "## we will use the above code when a column has mix data type like int and str\n",
    "## after this code str will be converted into NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> DataFrame.astype() </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# astype() Syntax\n",
    "DataFrame.astype(dtype, copy=True, errors='raise')\n",
    "\n",
    "## astype ka function datatype ko change karny ky liya use hota hai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Description |\n",
    "| :------: | :--------: |\n",
    "|dtype| – Accepts a numpy.dtype or Python type to cast entire pandas object to the same type. Use {col: dtype, …}, where col is a column label and dtype is a numpy.dtype or Python type to cast one or more of the DataFrame’s columns.|\n",
    "|copy| -Default True. Return a copy when copy=True (be very careful setting copy=False as changes to values then may propagate to other pandas objects).|\n",
    "|errors| – Default raise.Use ‘raise’ to generate exception when unable to cast due to invalid data for type.Use ‘ignore’ to not raise exception (supress errors/exceptions). On error return original object.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                          object\n",
       "beer_servings                     int64\n",
       "spirit_servings                   int64\n",
       "wine_servings                     int64\n",
       "total_litres_of_pure_alcohol    float64\n",
       "continent                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "\n",
    "## dtypes function dataframe ky har column ko data type ko check karne ke liya hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country                          object\n",
      "beer_servings                     int64\n",
      "spirit_servings                   int64\n",
      "wine_servings                     int64\n",
      "total_litres_of_pure_alcohol    float64\n",
      "continent                        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame from Dictionary\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\"],\n",
    "    'Fee' :[\"20000\",\"25000\",\"26000\"],\n",
    "    'Duration':['30day','40days','35days'],\n",
    "    'Discount':[\"1000\",\"2300\",\"1500\"]\n",
    "              }\n",
    "\n",
    "df_tech = pd.DataFrame(technologies)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses     object\n",
      "Fee          int32\n",
      "Duration    object\n",
      "Discount    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Change data type of column\n",
    "df_tech.Fee = df_tech.Fee.astype('int')\n",
    "#Alternate\n",
    "#df_tech.Fee = df['Fee'].astype('int')\n",
    "print(df_tech.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses      string\n",
      "Fee           int32\n",
      "Duration     object\n",
      "Discount    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# change data type of columns\n",
    "df_tech = df_tech.astype({'Courses':'string','Fee':'int','Discount':'float'})\n",
    "print(df_tech.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Spark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\git\\jaan_repo\\pandas_a_to_z\\pandas_a_to_z.ipynb Cell 71\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/git/jaan_repo/pandas_a_to_z/pandas_a_to_z.ipynb#Y165sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_tech\u001b[39m.\u001b[39mCourses \u001b[39m=\u001b[39m df_tech\u001b[39m.\u001b[39;49mCourses\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5920\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5913\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   5914\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   5915\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   5916\u001b[0m     ]\n\u001b[0;32m   5918\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5919\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 5920\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   5921\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5923\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 419\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 580\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    582\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    583\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m   1291\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1292\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m   1293\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m   1294\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1234\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     \u001b[39mreturn\u001b[39;00m values\n\u001b[0;32m   1232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(values, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   1233\u001b[0m     \u001b[39m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m-> 1234\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m   1236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\string_.py:446\u001b[0m, in \u001b[0;36mStringArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    443\u001b[0m     values[mask] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m    444\u001b[0m     \u001b[39mreturn\u001b[39;00m values\n\u001b[1;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mastype(dtype, copy)\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\base.py:584\u001b[0m, in \u001b[0;36mExtensionArray.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mconstruct_array_type()\n\u001b[0;32m    582\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_from_sequence(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m--> 584\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray(\u001b[39mself\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Jahanzaib\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py:129\u001b[0m, in \u001b[0;36mPandasArray.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: NpDtype \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ndarray, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Spark'"
     ]
    }
   ],
   "source": [
    "df_tech.Courses = df_tech.Courses.astype('int')\n",
    "\n",
    "## jab string(jis mein numeric value na ho) ko int mein change karny ki koshish karen gy to error aay ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses      string\n",
      "Fee           int32\n",
      "Duration     object\n",
      "Discount    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_tech.Courses = df_tech.Courses.astype('int', errors='ignore')\n",
    "print(df_tech.dtypes)\n",
    "\n",
    "## above error ko igrone karny ky liya error param mein ignore put kar den."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> pandas.DataFrame.mean() </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax of DataFrame.mean() \n",
    "DataFrame.mean(axis=None, skipna=None, level=None, numeric_only=None, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Description |\n",
    "|------|------|\n",
    "|axis| – Where to apply the mean rows/columns. For rows using index/0, for columns use column/1|\n",
    "|skipna| – Excludes all None/NaN from teh mean result. Default set to True|\n",
    "|level| – Use with multiindex. Takes int or level name, default None|\n",
    "|numeric_only| – Excludes all non numeric values. Considers only int, float & boolean. bool, default None|\n",
    "|**kwargs| – Additional keyword arguments to be passed to the function.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beer_servings                   106.160622\n",
      "spirit_servings                  80.994819\n",
      "wine_servings                    49.450777\n",
      "total_litres_of_pure_alcohol      4.717098\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jahanzaib\\AppData\\Local\\Temp\\ipykernel_436\\986055514.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  val = df.mean()\n"
     ]
    }
   ],
   "source": [
    "val = df.mean()\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 289.000000\n",
      "season            2012.029463\n",
      "dl_applied           0.025997\n",
      "win_by_runs         13.715771\n",
      "win_by_wickets       3.363951\n",
      "umpire3                   NaN\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jahanzaib\\AppData\\Local\\Temp\\ipykernel_436\\321238138.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  val1 = df1.mean()\n"
     ]
    }
   ],
   "source": [
    "val1 = df1.mean()\n",
    "print(val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 289.000000\n",
      "season            2012.029463\n",
      "dl_applied           0.025997\n",
      "win_by_runs         13.715771\n",
      "win_by_wickets       3.363951\n",
      "umpire3                   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean for all non numeric columns\n",
    "val2 = df1.mean(numeric_only=True)\n",
    "print(val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'beer_servings', 'spirit_servings', 'wine_servings',\n",
       "       'total_litres_of_pure_alcohol', 'continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beer_servings      106.160622\n",
      "spirit_servings     80.994819\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mean() on selected columns\n",
    "val3 = df[['beer_servings','spirit_servings']].mean()\n",
    "print(val3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore NaN from mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip NaN Values\n",
    "val4 = df.mean(axis=0,numeric_only=True,skipna=True)\n",
    "print(val4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mean on Column axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis = 1 for column axis\n",
    "val5 = df.mean(axis=1,numeric_only=True)\n",
    "print(val5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> pandas.DataFrame.where() </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.where() syntax\n",
    "DataFrame.where(cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=NoDefault.no_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Description |\n",
    "|------|------|\n",
    "|cond| – Accepts one or more conditions. Takes eithere bool Series/DataFrame, array-like, or callable|\n",
    "|other| – Value to replace with. Takes either scalar, Series/DataFrame, or callable|\n",
    "|inplace| – If True, it updates the existing DataFrame and return None. Default set to False.|\n",
    "|axis| – rows/columns axis. Takes int, default None|\n",
    "|level| – Alignment leve.|\n",
    "|errors| – Specify whether to raise any error in event of failure. Accepts str, {‘raise’, ‘ignore’}, default ‘raise’|\n",
    "|try_cast| – Cast teh result basck to input type. (Available since 1.3.0 version)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee  Discount Duration\n",
      "0    Spark  22000      1500   30days\n",
      "1  PySpark  25000      1000   50days\n",
      "2    Spark  23000      1200   30days\n",
      "3   Python  24000       800   35days\n",
      "4  PySpark  26000      1300   40days\n"
     ]
    }
   ],
   "source": [
    "technologies= {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Spark\",\"Python\",\"PySpark\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000],\n",
    "    'Discount':[1500,1000,1200,800,1300],\n",
    "    'Duration':['30days','50days','30days','35days','40days']\n",
    "          }\n",
    "tech_df21 = pd.DataFrame(technologies)\n",
    "print(tech_df21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses      Fee  Discount Duration\n",
      "0      NaN      NaN       NaN      NaN\n",
      "1  PySpark  25000.0    1000.0   50days\n",
      "2      NaN      NaN       NaN      NaN\n",
      "3   Python  24000.0     800.0   35days\n",
      "4  PySpark  26000.0    1300.0   40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Default example\n",
    "df4=tech_df21.where(tech_df21.Fee > 23000)\n",
    "print(df4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Discount Duration\n",
      "0       NA     NA       NA       NA\n",
      "1  PySpark  25000     1000   50days\n",
      "2       NA     NA       NA       NA\n",
      "3   Python  24000      800   35days\n",
      "4  PySpark  26000     1300   40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use other param\n",
    "df4=tech_df21.where(tech_df21.Fee > 23000,'NA')\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Columns & Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Discount Duration\n",
      "0       NA     NA       NA       NA\n",
      "1  PySpark  25000     1000   50days\n",
      "2       NA     NA       NA       NA\n",
      "3       NA     NA       NA       NA\n",
      "4  PySpark  26000     1300   40days\n"
     ]
    }
   ],
   "source": [
    "# Where on multiple columns & conditions\n",
    "cond1 = tech_df21.Fee > 23000\n",
    "cond2 = tech_df21.Discount > 900\n",
    "df5 = tech_df21.where(cond1 & cond2, other='NA') \n",
    "print(df5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating on existing DataFrame\n",
    "tech_df21.where(cond1 & cond2, 'NA', inplace=True) \n",
    "print(tech_df21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> dropna() </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.DataFrame.dropna() syntax\n",
    "DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r1    Spark  20000.0    30day     1000  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r4   Python  23093.0   45days     2500  NaN\n",
      "r5   pandas  24000.0      NaN      NaT  NaN\n",
      "r6      NaN      NaN      NaN      NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"pandas\",np.nan],\n",
    "    'Fee' :[20000,25000,26000,23093,24000,np.nan],\n",
    "    'Duration':['30day','40days','35days','45days',np.nan,np.nan],\n",
    "    'Discount':[1000,np.nan,1200,2500,pd.NaT,np.nan],\n",
    "    'NaN':[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "              }\n",
    "index_labels=['r1','r2','r3','r4','r5','r6']\n",
    "df = pd.DataFrame(technologies,index=index_labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r1    Spark  20000.0    30day     1000  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r4   Python  23093.0   45days     2500  NaN\n",
      "r5   pandas  24000.0      NaN      NaT  NaN\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that has all Nan Values\n",
    "df1 = df.dropna(how='all')\n",
    "print(df1)\n",
    "\n",
    "## how=all ka matlab hai ka jab tak row ki tamam values NaN hon to usy delete kar do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount\n",
      "r1    Spark  20000.0    30day     1000\n",
      "r2  PySpark  25000.0   40days      NaN\n",
      "r3   Hadoop  26000.0   35days     1200\n",
      "r4   Python  23093.0   45days     2500\n",
      "r5   pandas  24000.0      NaN      NaT\n",
      "r6      NaN      NaN      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that has all Nan Values\n",
    "df2 = df.dropna(how='all',axis=1)\n",
    "print(df2)\n",
    "\n",
    "## axis=1 put karny sy column delete ho ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses      Fee Duration Discount\n",
      "r1   Spark  20000.0    30day     1000\n",
      "r3  Hadoop  26000.0   35days     1200\n",
      "r4  Python  23093.0   45days     2500\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that contains nan values\n",
    "df3=df.dropna()\n",
    "print(df3)\n",
    "\n",
    "## is function ko apply karny sy jahan bhi NaN value ho gi wo column or rows delete ho jaen gi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dropna() on Specific Selected Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r1    Spark  20000.0    30day     1000  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r4   Python  23093.0   45days     2500  NaN\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that has NaN values on selected columns\n",
    "df4=df.dropna(subset=['Courses','Duration'])\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop NaN Values with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>Spark</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>30day</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>40days</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>35days</td>\n",
       "      <td>1200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>Python</td>\n",
       "      <td>23093.0</td>\n",
       "      <td>45days</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r5</th>\n",
       "      <td>pandas</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Courses      Fee Duration Discount  NaN\n",
       "r1    Spark  20000.0    30day     1000  NaN\n",
       "r2  PySpark  25000.0   40days      NaN  NaN\n",
       "r3   Hadoop  26000.0   35days     1200  NaN\n",
       "r4   Python  23093.0   45days     2500  NaN\n",
       "r5   pandas  24000.0      NaN      NaT  NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With threshold, \n",
    "# Keep only the rows with at least 2 non-NA values.\n",
    "df5=df.dropna(thresh=2)\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> pandas.DataFrame.fillna() </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax of pandas.DataFrame.fillna()\n",
    "DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Fuction|Discription|\n",
    "|:----:|:-----|\n",
    "|value|  Takes either scalar, dict, Series, or DataFrame but not list.|\n",
    "|method|  Takes one of these values {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}. Default None.\n",
    "|axis|  0 or ‘index’, 1 or ‘columns’. Used to specifiy axis to fill the values.|\n",
    "|inplace|  Default False. When used True, it updates existing DataFrame object.\n",
    "|limit|  Specify how many fills should happen. This is the maximum number of consecutive NaN values replaced with specified value.|\n",
    "|downcast|  It takes a dict of key-value pair that specifies data type to downcast . Like Float64 to int64, date to string e.t.c|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>Spark</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>30day</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>40days</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>35days</td>\n",
       "      <td>1200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>Python</td>\n",
       "      <td>23093.0</td>\n",
       "      <td>45days</td>\n",
       "      <td>2500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r5</th>\n",
       "      <td>pandas</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Courses      Fee Duration Discount  NaN\n",
       "r1    Spark  20000.0    30day     1000  NaN\n",
       "r2  PySpark  25000.0   40days      NaN  NaN\n",
       "r3   Hadoop  26000.0   35days     1200  NaN\n",
       "r4   Python  23093.0   45days     2500  NaN\n",
       "r5   pandas  24000.0      NaN      NaT  NaN\n",
       "r6      NaN      NaN      NaN      NaN  NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fillna NaN with None Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount   NaN\n",
      "r1    Spark  20000.0    30day     1000  None\n",
      "r2  PySpark  25000.0   40days     None  None\n",
      "r3   Hadoop  26000.0   35days     1200  None\n",
      "r4   Python  23093.0   45days     2500  None\n",
      "r5   pandas  24000.0     None     None  None\n",
      "r6     None     None     None     None  None\n"
     ]
    }
   ],
   "source": [
    "# fillna to replace all NaN\n",
    "df2=df.fillna('None')\n",
    "print(df2)\n",
    "\n",
    "## Agarorignal dataframe ko update karna hai to ~df.fillna('None', inplace=True)~ use kar den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill NaN in one specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount   NaN\n",
      "r1    Spark  20000.0    30day     1000  None\n",
      "r2  PySpark  25000.0   40days        0  None\n",
      "r3   Hadoop  26000.0   35days     1200  None\n",
      "r4   Python  23093.0   45days     2500  None\n",
      "r5   pandas  24000.0     None        0  None\n",
      "r6     None     None     None        0  None\n"
     ]
    }
   ],
   "source": [
    "# fillna on one column\n",
    "df2['Discount'] =  df['Discount'].fillna('0')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill NaN on multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount   NaN\n",
      "r1    Spark  20000.0    30day     1000  None\n",
      "r2  PySpark  25000.0   40days        0  None\n",
      "r3   Hadoop  26000.0   35days     1200  None\n",
      "r4   Python  23093.0   45days     2500  None\n",
      "r5   pandas  24000.0     None        0  None\n",
      "r6     None        0     None        0  None\n"
     ]
    }
   ],
   "source": [
    "# fillna() on multiple columns\n",
    "df2[['Discount','Fee']] =  df[['Discount','Fee']].fillna('0')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r1    Spark  20000.0    30day     1000  NaN\n",
      "r2  PySpark  25000.0   40days        0  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r4   Python  23093.0   45days     2500  NaN\n",
      "r5   pandas  24000.0      NaN        0  NaN\n",
      "r6      NaN  10000.0      NaN        0  NaN\n"
     ]
    }
   ],
   "source": [
    "# fillna() on multiple columns\n",
    "df2 =  df.fillna(value={'Discount':'0','Fee':10000})\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With limit Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration  Discount  NaN\n",
      "r1    Spark  20000.0    30day    1000.0  NaN\n",
      "r2  PySpark  25000.0   40days       0.0  NaN\n",
      "r3   Hadoop  26000.0   35days    1200.0  NaN\n",
      "r4   Python  23093.0   45days    2500.0  NaN\n",
      "r5   pandas  24000.0      NaN       0.0  NaN\n",
      "r6      NaN      0.0      NaN       NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# fill with limit\n",
    "df2=df.fillna(value={'Discount':0,'Fee':0},limit=2)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> loc[] </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Single Column & Row By Label using loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1      Spark\n",
      "r2    PySpark\n",
      "r3     Hadoop\n",
      "r4     Python\n",
      "r5     pandas\n",
      "r6        NaN\n",
      "Name: Courses, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select Single Column by label\n",
    "print(df.loc[:, \"Courses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses      Hadoop\n",
      "Fee         26000.0\n",
      "Duration     35days\n",
      "Discount       1200\n",
      "NaN             NaN\n",
      "Name: r3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select Single Row by label\n",
    "print(df.loc['r3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Multiple Rows & Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple Rows by Label\n",
    "print(df.loc[['r2','r3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Discount\n",
      "r1    Spark  20000.0     1000\n",
      "r2  PySpark  25000.0      NaN\n",
      "r3   Hadoop  26000.0     1200\n",
      "r4   Python  23093.0     2500\n",
      "r5   pandas  24000.0      NaT\n",
      "r6      NaN      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple Columns by labels\n",
    "print(df.loc[:, [\"Courses\",\"Fee\",\"Discount\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Between Two Rows or Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r1    Spark  20000.0    30day     1000  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r4   Python  23093.0   45days     2500  NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Rows Between two Index Labels\n",
    "# Includes both r1 and r4 rows\n",
    "print(df.loc['r1':'r4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fee Duration Discount\n",
      "r1  20000.0    30day     1000\n",
      "r2  25000.0   40days      NaN\n",
      "r3  26000.0   35days     1200\n",
      "r4  23093.0   45days     2500\n",
      "r5  24000.0      NaN      NaT\n",
      "r6      NaN      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Columns between two Labels\n",
    "# Includes both 'Fee' and 'Discount' columns\n",
    "print(df.loc[:,'Fee':'Discount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Alternate Rows or Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses      Fee Duration Discount  NaN\n",
      "r1   Spark  20000.0    30day     1000  NaN\n",
      "r3  Hadoop  26000.0   35days     1200  NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select Alternate rows By indeces\n",
    "print(df.loc['r1':'r4':2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fee Discount\n",
      "r1  20000.0     1000\n",
      "r2  25000.0      NaN\n",
      "r3  26000.0     1200\n",
      "r4  23093.0     2500\n",
      "r5  24000.0      NaT\n",
      "r6      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Alternate Columns between two Labels\n",
    "print(df.loc[:,'Fee':'Discount':2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Conditions with pandas loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r5   pandas  24000.0      NaN      NaT  NaN\n"
     ]
    }
   ],
   "source": [
    "# Using Conditions\n",
    "print(df.loc[df['Fee'] >= 24000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> iloc[] </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,iloc[start:stop:step,start:stop:step]\n",
    "\n",
    "## Comma sy pahly row or comma ky baad column ki detail hai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Single Row & Column By Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses     PySpark\n",
      "Fee         25000.0\n",
      "Duration     40days\n",
      "Discount        NaN\n",
      "NaN             NaN\n",
      "Name: r2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select Single Row by Index\n",
    "print(df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1      Spark\n",
      "r2    PySpark\n",
      "r3     Hadoop\n",
      "r4     Python\n",
      "r5     pandas\n",
      "r6        NaN\n",
      "Name: Courses, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select Single Column by Index\n",
    "print(df.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Multiple Rows & Columns by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple Rows by Index\n",
    "print(df.iloc[[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Discount\n",
      "r1    Spark  20000.0     1000\n",
      "r2  PySpark  25000.0      NaN\n",
      "r3   Hadoop  26000.0     1200\n",
      "r4   Python  23093.0     2500\n",
      "r5   pandas  24000.0      NaT\n",
      "r6      NaN      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple Columns by Index\n",
    "print(df.iloc[:, [0,1,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Rows or Columns by Index Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r1    Spark  20000.0    30day     1000  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r4   Python  23093.0   45days     2500  NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Rows Between two Indexs\n",
    "# Includes Index 0 & Execludes 4\n",
    "print(df.iloc[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fee Duration Discount\n",
      "r1  20000.0    30day     1000\n",
      "r2  25000.0   40days      NaN\n",
      "r3  26000.0   35days     1200\n",
      "r4  23093.0   45days     2500\n",
      "r5  24000.0      NaN      NaT\n",
      "r6      NaN      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Columns between two Indexes\n",
    "# Includes Index 1 & Execludes 4\n",
    "print(df.iloc[:,1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Alternate Rows or Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses      Fee Duration Discount  NaN\n",
      "r1   Spark  20000.0    30day     1000  NaN\n",
      "r3  Hadoop  26000.0   35days     1200  NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Alternate rows By Index\n",
    "print(df.iloc[0:4:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Fee Discount\n",
      "r1  20000.0     1000\n",
      "r2  25000.0      NaN\n",
      "r3  26000.0     1200\n",
      "r4  23093.0     2500\n",
      "r5  24000.0      NaT\n",
      "r6      NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "# Select Alternate Columns between two Indexes\n",
    "print(df.iloc[:,1:4:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Conditions with iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount  NaN\n",
      "r2  PySpark  25000.0   40days      NaN  NaN\n",
      "r3   Hadoop  26000.0   35days     1200  NaN\n",
      "r5   pandas  24000.0      NaN      NaT  NaN\n"
     ]
    }
   ],
   "source": [
    "# By Condition\n",
    "print(df.iloc[list(df['Fee'] >= 24000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> isin() </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax of isin() Function\n",
    "isin(values)\n",
    "\n",
    "## values – iterable, Series, DataFrame or dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration Discount\n",
      "0   Spark  20000    30day     1000\n"
     ]
    }
   ],
   "source": [
    "# Specific Value\n",
    "df_tech2=df_tech[df_tech['Courses'].isin(['Spark'])]\n",
    "print(df_tech2)\n",
    "\n",
    "## DataFrame mein kisi column sy kisi specific value find karny ky liya use hota hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration Discount\n",
      "0   Spark  20000    30day     1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_tech3=df_tech[df_tech['Courses'].isin(['Spark','Java'])]\n",
    "print(df_tech3)\n",
    "\n",
    "## isi function ko use karty hoy multiple values bhi finf ki ja sakti hen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spark</td>\n",
       "      <td>20000</td>\n",
       "      <td>30day</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000</td>\n",
       "      <td>40days</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>26000</td>\n",
       "      <td>35days</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Courses    Fee Duration Discount\n",
       "0    Spark  20000    30day     1000\n",
       "1  PySpark  25000   40days     2300\n",
       "2   Hadoop  26000   35days     1500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee  Duration  Discount\n",
      "0     True  False     False     False\n",
      "1    False   True     False     False\n",
      "2    False  False      True     False\n"
     ]
    }
   ],
   "source": [
    "# isin() with list of values\n",
    "print(df_tech.isin(['Spark','Python','25000','35days']))\n",
    "\n",
    "## is in function mein jab list pass karwaen gy to to jahan jahan value ho gi tru show kary ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee  Duration  Discount\n",
      "0     True  False     False     False\n",
      "1    False  False     False     False\n",
      "2     True  False     False     False\n"
     ]
    }
   ],
   "source": [
    "print(df_tech.isin({'Courses': ['Spark', 'Hadoop']}))\n",
    "\n",
    "## agar kisi specific column sy multiple values find karni ho to dic pass karwaen gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee  Duration  Discount\n",
      "0    False  False     False     False\n",
      "1    False   True     False     False\n",
      "2    False  False     False     False\n"
     ]
    }
   ],
   "source": [
    "# Checks in another DataFrame\n",
    "df_tech4 = pd.DataFrame({\n",
    "    'Courses' :['C++','Python',],\n",
    "    'Fee' :['23000','25000',],\n",
    "    'Duration':['30days','55days']\n",
    "          })\n",
    "print(df_tech.isin(df_tech4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> groupby() </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax of DataFrame.groupby()\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, \n",
    "       sort=True, group_keys=True, squeeze=<no_default>, \n",
    "       observed=False, dropna=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter | Description |\n",
    "| :------: | :--------: |\n",
    "|by| – List of column names to group by|\n",
    "|axis| – Default to 0. It takes 0 or ‘index’, 1 or ‘columns’|\n",
    "|level| – Used with MultiIndex.\n",
    "|as_index| – sql style grouped otput.|\n",
    "|sort| – Default to True. Specify whether to sort after group|\n",
    "|group_keys| – add group keys or not|\n",
    "|squeeze| – depricated in new versions|\n",
    "|observed| – This only applies if any of the groupers are Categoricals.|\n",
    "|dropna| – Default to False. Use True to drop None/Nan on sory keys|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spark</td>\n",
       "      <td>22000</td>\n",
       "      <td>30days</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000</td>\n",
       "      <td>50days</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>23000</td>\n",
       "      <td>55days</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>24000</td>\n",
       "      <td>40days</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pandas</td>\n",
       "      <td>26000</td>\n",
       "      <td>60days</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>25000</td>\n",
       "      <td>35days</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spark</td>\n",
       "      <td>25000</td>\n",
       "      <td>30days</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python</td>\n",
       "      <td>22000</td>\n",
       "      <td>50days</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NA</td>\n",
       "      <td>1500</td>\n",
       "      <td>40days</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Courses    Fee Duration  Discount\n",
       "0    Spark  22000   30days    1000.0\n",
       "1  PySpark  25000   50days    2300.0\n",
       "2   Hadoop  23000   55days    1000.0\n",
       "3   Python  24000   40days    1200.0\n",
       "4   Pandas  26000   60days    2500.0\n",
       "5   Hadoop  25000   35days       NaN\n",
       "6    Spark  25000   30days    1400.0\n",
       "7   Python  22000   50days    1600.0\n",
       "8       NA   1500   40days       0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",\"NA\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df_tech5 = pd.DataFrame(technologies)\n",
    "df_tech5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Hadoop   48000    1000.0\n",
      "NA        1500       0.0\n",
      "Pandas   26000    2500.0\n",
      "PySpark  25000    2300.0\n",
      "Python   46000    2800.0\n",
      "Spark    47000    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Use groupby() to compute the sum\n",
    "df_tech6 =df_tech5.groupby(['Courses']).sum()\n",
    "print(df_tech6)\n",
    "\n",
    "## df_tech5 ky dataframe mein sy courses ky column har unique value ko ikatha kar ky unki values ko sum kar diya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Fee  Discount\n",
      "Courses Duration                 \n",
      "Hadoop  35days    25000       0.0\n",
      "        55days    23000    1000.0\n",
      "NA      40days     1500       0.0\n",
      "Pandas  60days    26000    2500.0\n",
      "PySpark 50days    25000    2300.0\n",
      "Python  40days    24000    1200.0\n",
      "        50days    22000    1600.0\n",
      "Spark   30days    47000    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Group by multiple columns\n",
    "df_tech7 =df_tech5.groupby(['Courses', 'Duration']).sum()\n",
    "print(df_tech7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses Duration    Fee  Discount\n",
      "0   Hadoop   35days  25000       0.0\n",
      "1   Hadoop   55days  23000    1000.0\n",
      "2       NA   40days   1500       0.0\n",
      "3   Pandas   60days  26000    2500.0\n",
      "4  PySpark   50days  25000    2300.0\n",
      "5   Python   40days  24000    1200.0\n",
      "6   Python   50days  22000    1600.0\n",
      "7    Spark   30days  47000    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Add Row Index to the group by result\n",
    "df_tech8 = df_tech5.groupby(['Courses','Duration']).sum().reset_index()\n",
    "print(df_tech8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop NA/NaN/None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Hadoop   48000    1000.0\n",
      "NA        1500       0.0\n",
      "Pandas   26000    2500.0\n",
      "PySpark  25000    2300.0\n",
      "Python   46000    2800.0\n",
      "Spark    47000    2400.0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that have None/Nan on group keys\n",
    "df_tech9=df_tech5.groupby(by=['Courses'], dropna=False).sum()\n",
    "print(df_tech9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Spark    47000    2400.0\n",
      "PySpark  25000    2300.0\n",
      "Hadoop   48000    1000.0\n",
      "Python   46000    2800.0\n",
      "Pandas   26000    2500.0\n",
      "NA        1500       0.0\n"
     ]
    }
   ],
   "source": [
    "# Remove sorting on grouped results\n",
    "df_tech10=df_tech5.groupby(by=['Courses'], sort=False).sum()\n",
    "print(df_tech10)\n",
    "\n",
    "## By default sort parameter true hota hai or wo groupby ky baad data ko sort karta hai\n",
    "## Agar time ya performence issue hai to issy false kar den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Spark    47000    2400.0\n",
      "Python   46000    2800.0\n",
      "PySpark  25000    2300.0\n",
      "Pandas   26000    2500.0\n",
      "NA        1500       0.0\n",
      "Hadoop   48000    1000.0\n"
     ]
    }
   ],
   "source": [
    "# Sorting group keys on descending order\n",
    "groupedDF = df_tech5.groupby('Courses',sort=False).sum()\n",
    "sortedDF=groupedDF.sort_values('Courses', ascending=False)\n",
    "print(sortedDF)\n",
    "\n",
    "\n",
    "## Agar decending order mein sort karna hai to is code ko use karen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Courses</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Hadoop</th>\n",
       "      <th>2</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>23000</td>\n",
       "      <td>55days</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>25000</td>\n",
       "      <td>35days</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NA</th>\n",
       "      <th>8</th>\n",
       "      <td>NA</td>\n",
       "      <td>1500</td>\n",
       "      <td>40days</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pandas</th>\n",
       "      <th>4</th>\n",
       "      <td>Pandas</td>\n",
       "      <td>26000</td>\n",
       "      <td>60days</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PySpark</th>\n",
       "      <th>1</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000</td>\n",
       "      <td>50days</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Python</th>\n",
       "      <th>7</th>\n",
       "      <td>Python</td>\n",
       "      <td>22000</td>\n",
       "      <td>50days</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>24000</td>\n",
       "      <td>40days</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Spark</th>\n",
       "      <th>0</th>\n",
       "      <td>Spark</td>\n",
       "      <td>22000</td>\n",
       "      <td>30days</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spark</td>\n",
       "      <td>25000</td>\n",
       "      <td>30days</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Courses    Fee Duration  Discount\n",
       "Courses                                     \n",
       "Hadoop  2   Hadoop  23000   55days    1000.0\n",
       "        5   Hadoop  25000   35days       NaN\n",
       "NA      8       NA   1500   40days       0.0\n",
       "Pandas  4   Pandas  26000   60days    2500.0\n",
       "PySpark 1  PySpark  25000   50days    2300.0\n",
       "Python  7   Python  22000   50days    1600.0\n",
       "        3   Python  24000   40days    1200.0\n",
       "Spark   0    Spark  22000   30days    1000.0\n",
       "        6    Spark  25000   30days    1400.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Using apply() & lambda\n",
    "df_tech5.groupby('Courses').apply(lambda x: x.sort_values('Fee'))\n",
    "\n",
    "## Agar kisi or key kay mutabiq sort karna hai to lambda or apply function use karen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### groupby() + aggreagte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           min    max\n",
      "Courses              \n",
      "Hadoop   23000  25000\n",
      "NA        1500   1500\n",
      "Pandas   26000  26000\n",
      "PySpark  25000  25000\n",
      "Python   22000  24000\n",
      "Spark    22000  25000\n"
     ]
    }
   ],
   "source": [
    "# Groupby & multiple aggregations\n",
    "result = df_tech5.groupby('Courses')['Fee'].aggregate(['min','max'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Duration    Fee       \n",
      "           count    min    max\n",
      "Courses                       \n",
      "Hadoop         2  23000  25000\n",
      "NA             1   1500   1500\n",
      "Pandas         1  26000  26000\n",
      "PySpark        1  25000  25000\n",
      "Python         2  22000  24000\n",
      "Spark          2  22000  25000\n"
     ]
    }
   ],
   "source": [
    "# Groupby multiple columns & multiple aggregations\n",
    "result1 = df_tech5.groupby('Courses').aggregate({'Duration':'count','Fee':['min','max']})\n",
    "print(result1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> pandas.to_datetime() </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = dt.date(2022,8,21) # year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "8\n",
      "2022\n"
     ]
    }
   ],
   "source": [
    "print(today_date.day)\n",
    "print(today_date.month)\n",
    "print(today_date.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-22 09:33:20\n"
     ]
    }
   ],
   "source": [
    "today_datetime = dt.datetime(2022,8,22,9,33,20) # year, month, day ,hour,minutes,seconds\n",
    "print(today_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "8\n",
      "22\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(today_datetime.year)\n",
    "print(today_datetime.month)\n",
    "print(today_datetime.day)\n",
    "print(today_datetime.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pandas.to_datetime() syntax\n",
    "pandas.to_datetime(arg, errors='raise', dayfirst=False, yearfirst=False, \n",
    "     utc=None, format=None, exact=True, unit=None, \n",
    "     infer_datetime_format=False, origin='unix', cache=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Description |\n",
    "| :------: | :--------: |\n",
    "|arg |– An integer, string, float, list, or DataFrame/dict_like object to convert into a Datetime object.|\n",
    "|errors| – Take values raise, ignore or coerce. if ‘raise’ used, raise a KeyError when a dict-like mapper, index, or columns contains labels that are not present in the Index being transformed. Default set to ignore.|\n",
    "|dayfirst| – default set False, Boolean value places day first if True.|\n",
    "|yearfirst| – Boolean value places year first if True, the default set False.|\n",
    "|utc| – Boolean value, Returns the time in UTC DatetimeIndex if True.|\n",
    "|format| – String input to tell the position of the day, month, and year. default set None.|\n",
    "|exact| – Boolean value, If True, require an exact format match. – If False, allow the format to match anywhere in the target string.|\n",
    "|infer_datetime_formatbool| – If True and no format is given, attempt to infer the format of the datetime strings based on the first non-NaN element. the default set False.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> head() </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax of head() method\n",
    "DataFrame.head(n)\n",
    "Series.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0        AS  \n",
      "1                           4.9        EU  \n",
      "2                           0.7        AF  \n",
      "3                          12.4        EU  \n",
      "4                           5.9        AF  \n"
     ]
    }
   ],
   "source": [
    "# Default return 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0        AS  \n",
      "1                           4.9        EU  \n",
      "2                           0.7        AF  \n"
     ]
    }
   ],
   "source": [
    "# Top N rows\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0    Afghanistan              0                0              0   \n",
      "1        Albania             89              132             54   \n",
      "2        Algeria             25                0             14   \n",
      "3        Andorra            245              138            312   \n",
      "4         Angola            217               57             45   \n",
      "..           ...            ...              ...            ...   \n",
      "185      Uruguay            115               35            220   \n",
      "186   Uzbekistan             25              101              8   \n",
      "187      Vanuatu             21               18             11   \n",
      "188    Venezuela            333              100              3   \n",
      "189      Vietnam            111                2              1   \n",
      "\n",
      "     total_litres_of_pure_alcohol continent  \n",
      "0                             0.0        AS  \n",
      "1                             4.9        EU  \n",
      "2                             0.7        AF  \n",
      "3                            12.4        EU  \n",
      "4                             5.9        AF  \n",
      "..                            ...       ...  \n",
      "185                           6.6        SA  \n",
      "186                           2.4        AS  \n",
      "187                           0.9        OC  \n",
      "188                           7.7        SA  \n",
      "189                           2.0        AS  \n",
      "\n",
      "[190 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Except last N rows\n",
    "print(df.head(-3))\n",
    "\n",
    "## is parameter ki waja sy last 3 rows ko chor ky baqi answer milyga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Afghanistan\n",
      "1        Albania\n",
      "2        Algeria\n",
      "3        Andorra\n",
      "4         Angola\n",
      "Name: country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# head() example\n",
    "print(df['country'].head())\n",
    "\n",
    "## head() function series par bhi apply ho sakta hai.\n",
    "## or DataFrame ka har column aik series hota hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Afghanistan\n",
       "1        Albania\n",
       "2        Algeria\n",
       "3        Andorra\n",
       "4         Angola\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Unique Function </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola',\n",
       "       'Antigua & Barbuda', 'Argentina', 'Armenia', 'Australia',\n",
       "       'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh',\n",
       "       'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan',\n",
       "       'Bolivia', 'Bosnia-Herzegovina', 'Botswana', 'Brazil', 'Brunei',\n",
       "       'Bulgaria', 'Burkina Faso', 'Burundi', \"Cote d'Ivoire\",\n",
       "       'Cabo Verde', 'Cambodia', 'Cameroon', 'Canada',\n",
       "       'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia',\n",
       "       'Comoros', 'Congo', 'Cook Islands', 'Costa Rica', 'Croatia',\n",
       "       'Cuba', 'Cyprus', 'Czech Republic', 'North Korea', 'DR Congo',\n",
       "       'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador',\n",
       "       'Egypt', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia',\n",
       "       'Ethiopia', 'Fiji', 'Finland', 'France', 'Gabon', 'Gambia',\n",
       "       'Georgia', 'Germany', 'Ghana', 'Greece', 'Grenada', 'Guatemala',\n",
       "       'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Honduras',\n",
       "       'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq',\n",
       "       'Ireland', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan',\n",
       "       'Kazakhstan', 'Kenya', 'Kiribati', 'Kuwait', 'Kyrgyzstan', 'Laos',\n",
       "       'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Lithuania',\n",
       "       'Luxembourg', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives',\n",
       "       'Mali', 'Malta', 'Marshall Islands', 'Mauritania', 'Mauritius',\n",
       "       'Mexico', 'Micronesia', 'Monaco', 'Mongolia', 'Montenegro',\n",
       "       'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal',\n",
       "       'Netherlands', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria',\n",
       "       'Niue', 'Norway', 'Oman', 'Pakistan', 'Palau', 'Panama',\n",
       "       'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland',\n",
       "       'Portugal', 'Qatar', 'South Korea', 'Moldova', 'Romania',\n",
       "       'Russian Federation', 'Rwanda', 'St. Kitts & Nevis', 'St. Lucia',\n",
       "       'St. Vincent & the Grenadines', 'Samoa', 'San Marino',\n",
       "       'Sao Tome & Principe', 'Saudi Arabia', 'Senegal', 'Serbia',\n",
       "       'Seychelles', 'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia',\n",
       "       'Solomon Islands', 'Somalia', 'South Africa', 'Spain', 'Sri Lanka',\n",
       "       'Sudan', 'Suriname', 'Swaziland', 'Sweden', 'Switzerland', 'Syria',\n",
       "       'Tajikistan', 'Thailand', 'Macedonia', 'Timor-Leste', 'Togo',\n",
       "       'Tonga', 'Trinidad & Tobago', 'Tunisia', 'Turkey', 'Turkmenistan',\n",
       "       'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates',\n",
       "       'United Kingdom', 'Tanzania', 'USA', 'Uruguay', 'Uzbekistan',\n",
       "       'Vanuatu', 'Venezuela', 'Vietnam', 'Yemen', 'Zambia', 'Zimbabwe'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.unique()\n",
    "\n",
    "## with this code we can see the unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola',\n",
       "       'Antigua & Barbuda', 'Argentina', 'Armenia', 'Australia',\n",
       "       'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh',\n",
       "       'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan',\n",
       "       'Bolivia', 'Bosnia-Herzegovina', 'Botswana', 'Brazil', 'Brunei',\n",
       "       'Bulgaria', 'Burkina Faso', 'Burundi', \"Cote d'Ivoire\",\n",
       "       'Cabo Verde', 'Cambodia', 'Cameroon', 'Canada',\n",
       "       'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia',\n",
       "       'Comoros', 'Congo', 'Cook Islands', 'Costa Rica', 'Croatia',\n",
       "       'Cuba', 'Cyprus', 'Czech Republic', 'North Korea', 'DR Congo',\n",
       "       'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador',\n",
       "       'Egypt', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia',\n",
       "       'Ethiopia', 'Fiji', 'Finland', 'France', 'Gabon', 'Gambia',\n",
       "       'Georgia', 'Germany', 'Ghana', 'Greece', 'Grenada', 'Guatemala',\n",
       "       'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Honduras',\n",
       "       'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran', 'Iraq',\n",
       "       'Ireland', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan',\n",
       "       'Kazakhstan', 'Kenya', 'Kiribati', 'Kuwait', 'Kyrgyzstan', 'Laos',\n",
       "       'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Lithuania',\n",
       "       'Luxembourg', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives',\n",
       "       'Mali', 'Malta', 'Marshall Islands', 'Mauritania', 'Mauritius',\n",
       "       'Mexico', 'Micronesia', 'Monaco', 'Mongolia', 'Montenegro',\n",
       "       'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal',\n",
       "       'Netherlands', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria',\n",
       "       'Niue', 'Norway', 'Oman', 'Pakistan', 'Palau', 'Panama',\n",
       "       'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland',\n",
       "       'Portugal', 'Qatar', 'South Korea', 'Moldova', 'Romania',\n",
       "       'Russian Federation', 'Rwanda', 'St. Kitts & Nevis', 'St. Lucia',\n",
       "       'St. Vincent & the Grenadines', 'Samoa', 'San Marino',\n",
       "       'Sao Tome & Principe', 'Saudi Arabia', 'Senegal', 'Serbia',\n",
       "       'Seychelles', 'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia',\n",
       "       'Solomon Islands', 'Somalia', 'South Africa', 'Spain', 'Sri Lanka',\n",
       "       'Sudan', 'Suriname', 'Swaziland', 'Sweden', 'Switzerland', 'Syria',\n",
       "       'Tajikistan', 'Thailand', 'Macedonia', 'Timor-Leste', 'Togo',\n",
       "       'Tonga', 'Trinidad & Tobago', 'Tunisia', 'Turkey', 'Turkmenistan',\n",
       "       'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates',\n",
       "       'United Kingdom', 'Tanzania', 'USA', 'Uruguay', 'Uzbekistan',\n",
       "       'Vanuatu', 'Venezuela', 'Vietnam', 'Yemen', 'Zambia', 'Zimbabwe'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     13\n",
       "0.1      7\n",
       "2.2      6\n",
       "6.3      5\n",
       "4.9      4\n",
       "        ..\n",
       "12.9     1\n",
       "0.8      1\n",
       "5.5      1\n",
       "9.3      1\n",
       "8.7      1\n",
       "Name: total_litres_of_pure_alcohol, Length: 90, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_litres_of_pure_alcohol'].value_counts()\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_litres_of_pure_alcohol'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>season</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>toss_winner</th>\n",
       "      <th>toss_decision</th>\n",
       "      <th>result</th>\n",
       "      <th>dl_applied</th>\n",
       "      <th>winner</th>\n",
       "      <th>win_by_runs</th>\n",
       "      <th>win_by_wickets</th>\n",
       "      <th>player_of_match</th>\n",
       "      <th>venue</th>\n",
       "      <th>umpire1</th>\n",
       "      <th>umpire2</th>\n",
       "      <th>umpire3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>2008-04-18</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>field</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>BB McCullum</td>\n",
       "      <td>M Chinnaswamy Stadium</td>\n",
       "      <td>Asad Rauf</td>\n",
       "      <td>RE Koertzen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>2008-04-19</td>\n",
       "      <td>Chennai Super Kings</td>\n",
       "      <td>Kings XI Punjab</td>\n",
       "      <td>Chennai Super Kings</td>\n",
       "      <td>bat</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Chennai Super Kings</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>MEK Hussey</td>\n",
       "      <td>Punjab Cricket Association Stadium, Mohali</td>\n",
       "      <td>MR Benson</td>\n",
       "      <td>SL Shastri</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>2008-04-19</td>\n",
       "      <td>Rajasthan Royals</td>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>Rajasthan Royals</td>\n",
       "      <td>bat</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Delhi Daredevils</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>MF Maharoof</td>\n",
       "      <td>Feroz Shah Kotla</td>\n",
       "      <td>Aleem Dar</td>\n",
       "      <td>GA Pratapkumar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2008-04-20</td>\n",
       "      <td>Mumbai Indians</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>Mumbai Indians</td>\n",
       "      <td>bat</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Royal Challengers Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>MV Boucher</td>\n",
       "      <td>Wankhede Stadium</td>\n",
       "      <td>SJ Davis</td>\n",
       "      <td>DJ Harper</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2008-04-20</td>\n",
       "      <td>Deccan Chargers</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>Deccan Chargers</td>\n",
       "      <td>bat</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Kolkata Knight Riders</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>DJ Hussey</td>\n",
       "      <td>Eden Gardens</td>\n",
       "      <td>BF Bowden</td>\n",
       "      <td>K Hariharan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  season        city        date                  team1  \\\n",
       "0   1    2008   Bangalore  2008-04-18  Kolkata Knight Riders   \n",
       "1   2    2008  Chandigarh  2008-04-19    Chennai Super Kings   \n",
       "2   3    2008       Delhi  2008-04-19       Rajasthan Royals   \n",
       "3   4    2008      Mumbai  2008-04-20         Mumbai Indians   \n",
       "4   5    2008     Kolkata  2008-04-20        Deccan Chargers   \n",
       "\n",
       "                         team2                  toss_winner toss_decision  \\\n",
       "0  Royal Challengers Bangalore  Royal Challengers Bangalore         field   \n",
       "1              Kings XI Punjab          Chennai Super Kings           bat   \n",
       "2             Delhi Daredevils             Rajasthan Royals           bat   \n",
       "3  Royal Challengers Bangalore               Mumbai Indians           bat   \n",
       "4        Kolkata Knight Riders              Deccan Chargers           bat   \n",
       "\n",
       "   result  dl_applied                       winner  win_by_runs  \\\n",
       "0  normal           0        Kolkata Knight Riders          140   \n",
       "1  normal           0          Chennai Super Kings           33   \n",
       "2  normal           0             Delhi Daredevils            0   \n",
       "3  normal           0  Royal Challengers Bangalore            0   \n",
       "4  normal           0        Kolkata Knight Riders            0   \n",
       "\n",
       "   win_by_wickets player_of_match                                       venue  \\\n",
       "0               0     BB McCullum                       M Chinnaswamy Stadium   \n",
       "1               0      MEK Hussey  Punjab Cricket Association Stadium, Mohali   \n",
       "2               9     MF Maharoof                            Feroz Shah Kotla   \n",
       "3               5      MV Boucher                            Wankhede Stadium   \n",
       "4               5       DJ Hussey                                Eden Gardens   \n",
       "\n",
       "     umpire1         umpire2  umpire3  \n",
       "0  Asad Rauf     RE Koertzen      NaN  \n",
       "1  MR Benson      SL Shastri      NaN  \n",
       "2  Aleem Dar  GA Pratapkumar      NaN  \n",
       "3   SJ Davis       DJ Harper      NaN  \n",
       "4  BF Bowden     K Hariharan      NaN  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'season', 'city', 'date', 'team1', 'team2', 'toss_winner',\n",
       "       'toss_decision', 'result', 'dl_applied', 'winner', 'win_by_runs',\n",
       "       'win_by_wickets', 'player_of_match', 'venue', 'umpire1', 'umpire2',\n",
       "       'umpire3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M Chinnaswamy Stadium                                   58\n",
       "Eden Gardens                                            54\n",
       "Feroz Shah Kotla                                        53\n",
       "Wankhede Stadium                                        49\n",
       "MA Chidambaram Stadium, Chepauk                         48\n",
       "Rajiv Gandhi International Stadium, Uppal               41\n",
       "Punjab Cricket Association Stadium, Mohali              35\n",
       "Sawai Mansingh Stadium                                  33\n",
       "Dr DY Patil Sports Academy                              17\n",
       "Subrata Roy Sahara Stadium                              17\n",
       "Kingsmead                                               15\n",
       "SuperSport Park                                         12\n",
       "Sardar Patel Stadium, Motera                            12\n",
       "Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium     11\n",
       "Brabourne Stadium                                       11\n",
       "Himachal Pradesh Cricket Association Stadium             9\n",
       "New Wanderers Stadium                                    8\n",
       "Maharashtra Cricket Association Stadium                  8\n",
       "Newlands                                                 7\n",
       "Barabati Stadium                                         7\n",
       "Punjab Cricket Association IS Bindra Stadium, Mohali     7\n",
       "St George's Park                                         7\n",
       "Dubai International Cricket Stadium                      7\n",
       "JSCA International Stadium Complex                       7\n",
       "Sheikh Zayed Stadium                                     7\n",
       "Sharjah Cricket Stadium                                  6\n",
       "Shaheed Veer Narayan Singh International Stadium         6\n",
       "Saurashtra Cricket Association Stadium                   5\n",
       "Nehru Stadium                                            5\n",
       "De Beers Diamond Oval                                    3\n",
       "Vidarbha Cricket Association Stadium, Jamtha             3\n",
       "Buffalo Park                                             3\n",
       "OUTsurance Oval                                          2\n",
       "Holkar Cricket Stadium                                   2\n",
       "Green Park                                               2\n",
       "Name: venue, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df1['venue'])\n",
    "\n",
    "## to see the all unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> pandas.DataFrame.join() </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.join(other, on=None, how='left', lsuffix= ' ', rsuffix= ' ', sort =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Function | Description |\n",
    "| :------: | :--------: |\n",
    "|other |Pass Right DataFrame object or list of DataFrame Objects|\n",
    "|on| Specify which index you want to join on when you have multiple indexes |\n",
    "| how|use to specify the join type. Accepts *inner*,*left*,*right*,*outer*|\n",
    "|lsuffix|Specify the left suffix string to column names|\n",
    "|rsuffix|Specify the right suffix string to column names|\n",
    "|sort|To specify the results to be sorted|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agar *lsuffix* or *rsuffix* define nahi karen gy to columns overlap error aay ga\n",
    "Left or Right suffix ki jo value put karen gy wohi duplicate collumns ka label mein show ho ga.\n",
    "- Agar kuch nahi likhna chahty to just space enter kar den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "      <th>name</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>100 g</td>\n",
       "      <td>381.0</td>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>Nuts, pecans</td>\n",
       "      <td>100 g</td>\n",
       "      <td>691.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>100 g</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>Teff, uncooked</td>\n",
       "      <td>100 g</td>\n",
       "      <td>367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>Sherbet, orange</td>\n",
       "      <td>100 g</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cauliflower, raw</td>\n",
       "      <td>0.3 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taro leaves, raw</td>\n",
       "      <td>0.7 g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  serving_size  calories              name total_fat\n",
       "f1       Cornstarch        100 g     381.0        Cornstarch     0.1 g\n",
       "f2     Nuts, pecans        100 g     691.0               NaN       NaN\n",
       "f3    Eggplant, raw        100 g      25.0     Eggplant, raw     0.2 g\n",
       "f4   Teff, uncooked        100 g     367.0               NaN       NaN\n",
       "f5  Sherbet, orange        100 g     144.0               NaN       NaN\n",
       "f6              NaN          NaN       NaN  Cauliflower, raw     0.3 g\n",
       "f7              NaN          NaN       NaN  Taro leaves, raw     0.7 g"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df1.join(df2,lsuffix=\" \", how = 'outer')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>100 g</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>Nuts, pecans</td>\n",
       "      <td>100 g</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>100 g</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>Teff, uncooked</td>\n",
       "      <td>100 g</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>Sherbet, orange</td>\n",
       "      <td>100 g</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name serving_size  calories\n",
       "f1       Cornstarch        100 g       381\n",
       "f2     Nuts, pecans        100 g       691\n",
       "f3    Eggplant, raw        100 g        25\n",
       "f4   Teff, uncooked        100 g       367\n",
       "f5  Sherbet, orange        100 g       144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating first DataFrame\n",
    "food1 = {\n",
    "    'name' :['Cornstarch','Nuts, pecans','Eggplant, raw','Teff, uncooked','Sherbet, orange'],\n",
    "    'serving_size' :['100 g', '100 g','100 g','100 g','100 g'],\n",
    "    'calories' :[381, 691, 25, 367, 144]\n",
    "}\n",
    "index_labels1 = ['f1','f2','f3','f4','f5']\n",
    "df1 = pd.DataFrame(food1, index =index_labels1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>Cauliflower, raw</td>\n",
       "      <td>0.3 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>Taro leaves, raw</td>\n",
       "      <td>0.7 g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name total_fat\n",
       "f1        Cornstarch     0.1 g\n",
       "f6  Cauliflower, raw     0.3 g\n",
       "f3     Eggplant, raw     0.2 g\n",
       "f7  Taro leaves, raw     0.7 g"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Second DataFrame\n",
    "food2 = {\n",
    "    'name' :['Cornstarch','Cauliflower, raw','Eggplant, raw','Taro leaves, raw'],\n",
    "    'total_fat' :['0.1 g', '0.3 g','0.2 g','0.7 g'],\n",
    "}\n",
    "index_labels2 = ['f1','f6','f3','f7']\n",
    "df2 = pd.DataFrame(food2, index =index_labels2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agar *how* mention nahi karen gy to first DataFrame ki rows hi second ky hisab sy update hon gi\n",
    "- Nechy result mein daikhen to first DataFrame ki tamam rows mojood hen or un men second DataFrame ky *total_fat* ki values update ho gae hen \n",
    "- Second DataFrame ki koe bhi new row add nhi hoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_left</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "      <th>name_right</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>100 g</td>\n",
       "      <td>381</td>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>Nuts, pecans</td>\n",
       "      <td>100 g</td>\n",
       "      <td>691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>100 g</td>\n",
       "      <td>25</td>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>Teff, uncooked</td>\n",
       "      <td>100 g</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>Sherbet, orange</td>\n",
       "      <td>100 g</td>\n",
       "      <td>144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_left serving_size  calories     name_right total_fat\n",
       "f1       Cornstarch        100 g       381     Cornstarch     0.1 g\n",
       "f2     Nuts, pecans        100 g       691            NaN       NaN\n",
       "f3    Eggplant, raw        100 g        25  Eggplant, raw     0.2 g\n",
       "f4   Teff, uncooked        100 g       367            NaN       NaN\n",
       "f5  Sherbet, orange        100 g       144            NaN       NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without how parameter\n",
    "df3 = df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agar *how* ko 'inner' put karen gy to donon DataFrames ki sirf wo rows hi rahen gi jinka index same ho ga.\n",
    "- inner join ny **df1** sy f2,f4,f5 or **df2** sy f6, f7 frop kar den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_left</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "      <th>name_right</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>100 g</td>\n",
       "      <td>381</td>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>100 g</td>\n",
       "      <td>25</td>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name_left serving_size  calories     name_right total_fat\n",
       "f1     Cornstarch        100 g       381     Cornstarch     0.1 g\n",
       "f3  Eggplant, raw        100 g        25  Eggplant, raw     0.2 g"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inner join\n",
    "df4 = df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how= 'inner')\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Right Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Right join mein second DataFrame ki sari rows hon gi magar first ki sirf wo hon gi jo second mein bhi hen \n",
    "- magar column donon ky hon gy \n",
    "- Jo column common hon gy unky duplicate(right,left) ban jaen gy\n",
    "- First ki jo values second mein nahi hon gi wahan NaN aa jay ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_left</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "      <th>name_right</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>100 g</td>\n",
       "      <td>381.0</td>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cauliflower, raw</td>\n",
       "      <td>0.3 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>100 g</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taro leaves, raw</td>\n",
       "      <td>0.7 g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name_left serving_size  calories        name_right total_fat\n",
       "f1     Cornstarch        100 g     381.0        Cornstarch     0.1 g\n",
       "f6            NaN          NaN       NaN  Cauliflower, raw     0.3 g\n",
       "f3  Eggplant, raw        100 g      25.0     Eggplant, raw     0.2 g\n",
       "f7            NaN          NaN       NaN  Taro leaves, raw     0.7 g"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# right join\n",
    "df5 = df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how= 'right')\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Left Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Left join mein First DataFrame ki sari rows hon gi magar second ki sirf wo hon gi jo first mein bhi hen \n",
    "- magar column donon ky hon gy \n",
    "- Jo column common hon gy unky duplicate(right,left) ban jaen gy\n",
    "- Second ki jo values first mein nahi hon gi wahan NaN aa jay ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_left</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "      <th>name_right</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>100 g</td>\n",
       "      <td>381</td>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>Nuts, pecans</td>\n",
       "      <td>100 g</td>\n",
       "      <td>691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>100 g</td>\n",
       "      <td>25</td>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>Teff, uncooked</td>\n",
       "      <td>100 g</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>Sherbet, orange</td>\n",
       "      <td>100 g</td>\n",
       "      <td>144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_left serving_size  calories     name_right total_fat\n",
       "f1       Cornstarch        100 g       381     Cornstarch     0.1 g\n",
       "f2     Nuts, pecans        100 g       691            NaN       NaN\n",
       "f3    Eggplant, raw        100 g        25  Eggplant, raw     0.2 g\n",
       "f4   Teff, uncooked        100 g       367            NaN       NaN\n",
       "f5  Sherbet, orange        100 g       144            NaN       NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# left join\n",
    "df6 = df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how= 'left')\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- outer join mein donon DataFrames ki rows shamil hon gi\n",
    "- First DataFrame ki jo values Second mein nahi hen ya Second ki jo values first mein nahi hen wahan NaN aa jay ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df1** or **df2** mein jo columns common thy unky left or right versions ban gay.\n",
    "- jo rows common hen wo donon mein aaen gi\n",
    "- jo rows sirf **df1** mein hen wo left waly column mein aaen gi\n",
    "- jo rows sirf **df2** mein hen wo right waly column mein aaen gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_left</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "      <th>name_right</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>100 g</td>\n",
       "      <td>381.0</td>\n",
       "      <td>Cornstarch</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>Nuts, pecans</td>\n",
       "      <td>100 g</td>\n",
       "      <td>691.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>100 g</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Eggplant, raw</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>Teff, uncooked</td>\n",
       "      <td>100 g</td>\n",
       "      <td>367.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>Sherbet, orange</td>\n",
       "      <td>100 g</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cauliflower, raw</td>\n",
       "      <td>0.3 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Taro leaves, raw</td>\n",
       "      <td>0.7 g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_left serving_size  calories        name_right total_fat\n",
       "f1       Cornstarch        100 g     381.0        Cornstarch     0.1 g\n",
       "f2     Nuts, pecans        100 g     691.0               NaN       NaN\n",
       "f3    Eggplant, raw        100 g      25.0     Eggplant, raw     0.2 g\n",
       "f4   Teff, uncooked        100 g     367.0               NaN       NaN\n",
       "f5  Sherbet, orange        100 g     144.0               NaN       NaN\n",
       "f6              NaN          NaN       NaN  Cauliflower, raw     0.3 g\n",
       "f7              NaN          NaN       NaN  Taro leaves, raw     0.7 g"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how = 'outer')\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join on Column\n",
    "\n",
    "Yani agar koe column donon DataFrames mein common hai to usky hisab sy join karny ka liya\n",
    "- pandas.merge() function use karen\n",
    "- ya phir us column ko index bna dy (kunka join function index ka hisab sy kaam karta hai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serving_size</th>\n",
       "      <th>calories</th>\n",
       "      <th>total_fat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cauliflower, raw</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cornstarch</th>\n",
       "      <td>100 g</td>\n",
       "      <td>381.0</td>\n",
       "      <td>0.1 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eggplant, raw</th>\n",
       "      <td>100 g</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.2 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nuts, pecans</th>\n",
       "      <td>100 g</td>\n",
       "      <td>691.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sherbet, orange</th>\n",
       "      <td>100 g</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taro leaves, raw</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7 g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teff, uncooked</th>\n",
       "      <td>100 g</td>\n",
       "      <td>367.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 serving_size  calories total_fat\n",
       "name                                             \n",
       "Cauliflower, raw          NaN       NaN     0.3 g\n",
       "Cornstarch              100 g     381.0     0.1 g\n",
       "Eggplant, raw           100 g      25.0     0.2 g\n",
       "Nuts, pecans            100 g     691.0       NaN\n",
       "Sherbet, orange         100 g     144.0       NaN\n",
       "Taro leaves, raw          NaN       NaN     0.7 g\n",
       "Teff, uncooked          100 g     367.0       NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = df1.set_index('name').join(df2.set_index('name'),  how = 'outer')\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56b2d59c60e4f87487f41cc5e6e8f6aa7185f560bca4a918a113fd85cb7bd9a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
